{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ea4e5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:14:24.995575Z",
     "start_time": "2023-12-01T14:14:24.891319Z"
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-v0.1\"\n",
    "# headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "# def query(payload):\n",
    "# \tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "# \treturn response.json()\n",
    "\n",
    "# output = query({\n",
    "# \t\"inputs\": \"Here are the documents ranked by relevance, with titles and keywords, from most relevant to least relevant, for the topic of 'Algorithms for routing around a rectangle':\\ntitle: \\\"Algorithms for routing around a rectangle\\\" with keywords: [algorithm, routing, three, time, developed]\\ntitle: \\\"A linear-time algorithm for four-partitioning four-connected planar graphs\\\" with keywords: [graph, algorithm, vertex, n_i, find]\\ntitle: \\\"A Linear-Time Algorithm to Find Four Independent Spanning Trees in Four-Connected Planar Graphs\\\" with keywords: [tree, vertex, find, graph, rooted]\\ntitle: \\\"Convex grid drawings of plane graphs with rectangular contours\\\" with keywords: [drawing, grid, convex, leaf, triconnected]\\ntitle: \\\"Rectangular drawings of planar graphs\\\" with keywords: [drawn, drawing, graph, rectangular, plane]\\n\\nGiven above information, for an author who has written the paper with the title \\\"Algorithms for routing around a rectangle\\\", which reference is related? Just answer 2 or 3 without explanation. 2 is \\\"Reliable broadcasting in product networks with Byzantine faults\\\", 3 is \\\"Auctions with heterogeneous items and budget limits\\\"\",\n",
    "# })\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3864b447a2f210f0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T16:13:22.639634Z",
     "start_time": "2023-12-01T16:13:17.556166Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from src.utils import default_data_path, config_to_env\n",
    "from src.task import LaMPTask\n",
    "from src.models import (\n",
    "    feed_prompt_to_lm,\n",
    "    OpenAIModel,\n",
    "    task_1_parse_response,\n",
    "    DistilBERTModel,\n",
    "    BERTSERINIModel,\n",
    "    MiniLM,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c2cf6fc51de78b4d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4dec76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:13:22.644620Z",
     "start_time": "2023-12-01T16:13:22.641743Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "config_to_env(\"OPENAI_API_KEY\")\n",
    "config_to_env(\"HUGGING_FACE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2838d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T16:13:22.649743Z",
     "start_time": "2023-12-01T16:13:22.647298Z"
    }
   },
   "outputs": [],
   "source": [
    "OpenAI_Subscriber = lambda prompts, ret: feed_prompt_to_lm(\n",
    "    model=OpenAIModel(), prompts=prompts, ret=ret, callback=task_1_parse_response\n",
    ")\n",
    "DistilBERT_Subscriber = lambda prompts, ret: feed_prompt_to_lm(\n",
    "    model=DistilBERTModel(), prompts=prompts, ret=ret, callback=task_1_parse_response\n",
    ")\n",
    "\n",
    "BERTSERINI_Subscriber = lambda prompts, ret: feed_prompt_to_lm(\n",
    "    model=BERTSERINIModel(), prompts=prompts, ret=ret, callback=task_1_parse_response\n",
    ")\n",
    "MiniLM_Subscriber = lambda prompts, ret: feed_prompt_to_lm(\n",
    "    model=MiniLM(), prompts=prompts, ret=ret, callback=task_1_parse_response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1fa06ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T15:29:40.008238Z",
     "start_time": "2023-12-01T15:29:40.005106Z"
    }
   },
   "outputs": [],
   "source": [
    "task_1_train_with_keyword = LaMPTask(\n",
    "    \"./src/data/LaMP_11_dev_questions.json\",\n",
    "    \"./src/data/LaMP_11_dev_outputs.json\",\n",
    "    # \"./src/data/LaMP_11_dev_questions.json\",\n",
    "    # \"./src/data/LaMP_11_dev_outputs.json\",\n",
    "    subscribers={\n",
    "        # \"BERTSERINI\": BERTSERINI_Subscriber,\n",
    "        # \"DistilBERT\": DistilBERT_Subscriber,\n",
    "        # \"MiniLM\": MiniLM_Subscriber,\n",
    "        \"OpenAI\": OpenAI_Subscriber,\n",
    "    },\n",
    "    # subscribers={},\n",
    "    prompt_save_path=default_data_path,\n",
    ")\n",
    "# task_1_train.construct_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0bcc35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T15:39:59.434831Z",
     "start_time": "2023-12-01T15:29:46.457677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIModel is processing the questions\n",
      "OpenAIModel is processing the question 010\n",
      "OpenAIModel finished the question 010 took 2.124704122543335\n",
      "OpenAIModel is processing the question 011\n",
      "OpenAIModel finished the question 011 took 0.9363250732421875\n",
      "OpenAIModel is processing the question 012\n",
      "OpenAIModel finished the question 012 took 1.6368708610534668\n",
      "OpenAIModel is processing the question 013\n",
      "OpenAIModel finished the question 013 took 1.8436269760131836\n",
      "OpenAIModel is processing the question 014\n",
      "OpenAIModel finished the question 014 took 0.5751352310180664\n",
      "OpenAIModel is processing the question 015\n",
      "OpenAIModel finished the question 015 took 2.2574801445007324\n",
      "OpenAIModel is processing the question 016\n",
      "OpenAIModel finished the question 016 took 0.7145438194274902\n",
      "OpenAIModel is processing the question 017\n",
      "OpenAIModel finished the question 017 took 2.0635159015655518\n",
      "OpenAIModel is processing the question 018\n",
      "OpenAIModel finished the question 018 took 0.5305278301239014\n",
      "OpenAIModel is processing the question 019\n",
      "OpenAIModel finished the question 019 took 0.6035110950469971\n",
      "OpenAIModel is processing the question 0110\n",
      "OpenAIModel finished the question 0110 took 1.13486909866333\n",
      "OpenAIModel is processing the question 0111\n",
      "OpenAIModel finished the question 0111 took 2.7015790939331055\n",
      "OpenAIModel is processing the question 0112\n",
      "OpenAIModel finished the question 0112 took 0.6256420612335205\n",
      "OpenAIModel is processing the question 0113\n",
      "OpenAIModel finished the question 0113 took 0.5837647914886475\n",
      "OpenAIModel is processing the question 0114\n",
      "OpenAIModel finished the question 0114 took 0.6777501106262207\n",
      "OpenAIModel is processing the question 0115\n",
      "OpenAIModel finished the question 0115 took 0.5450530052185059\n",
      "OpenAIModel is processing the question 0116\n",
      "OpenAIModel finished the question 0116 took 0.6336579322814941\n",
      "OpenAIModel is processing the question 0117\n",
      "OpenAIModel finished the question 0117 took 0.6946990489959717\n",
      "OpenAIModel is processing the question 0118\n",
      "OpenAIModel finished the question 0118 took 0.8334457874298096\n",
      "OpenAIModel is processing the question 0119\n",
      "OpenAIModel finished the question 0119 took 1.5389819145202637\n",
      "OpenAIModel is processing the question 0120\n",
      "OpenAIModel finished the question 0120 took 0.9433279037475586\n",
      "OpenAIModel is processing the question 0121\n",
      "OpenAIModel finished the question 0121 took 0.6331110000610352\n",
      "OpenAIModel is processing the question 0122\n",
      "OpenAIModel finished the question 0122 took 0.7326278686523438\n",
      "OpenAIModel is processing the question 0123\n",
      "OpenAIModel finished the question 0123 took 0.7311840057373047\n",
      "OpenAIModel is processing the question 0124\n",
      "OpenAIModel finished the question 0124 took 0.6209681034088135\n",
      "OpenAIModel is processing the question 0125\n",
      "OpenAIModel finished the question 0125 took 0.6772060394287109\n",
      "OpenAIModel is processing the question 0126\n",
      "OpenAIModel finished the question 0126 took 0.5952560901641846\n",
      "OpenAIModel is processing the question 0127\n",
      "OpenAIModel finished the question 0127 took 0.7301099300384521\n",
      "OpenAIModel is processing the question 0128\n",
      "OpenAIModel finished the question 0128 took 0.7762200832366943\n",
      "OpenAIModel is processing the question 0129\n",
      "OpenAIModel finished the question 0129 took 0.7845580577850342\n",
      "OpenAIModel is processing the question 0130\n",
      "OpenAIModel finished the question 0130 took 0.5253911018371582\n",
      "OpenAIModel is processing the question 0131\n",
      "OpenAIModel finished the question 0131 took 2.3683459758758545\n",
      "OpenAIModel is processing the question 0132\n",
      "OpenAIModel finished the question 0132 took 4.1186158657073975\n",
      "OpenAIModel is processing the question 0133\n",
      "OpenAIModel finished the question 0133 took 0.557440996170044\n",
      "OpenAIModel is processing the question 0134\n",
      "OpenAIModel finished the question 0134 took 1.1969382762908936\n",
      "OpenAIModel is processing the question 0135\n",
      "OpenAIModel finished the question 0135 took 2.165584087371826\n",
      "OpenAIModel is processing the question 0136\n",
      "OpenAIModel finished the question 0136 took 0.7297742366790771\n",
      "OpenAIModel is processing the question 0137\n",
      "OpenAIModel finished the question 0137 took 2.6173980236053467\n",
      "OpenAIModel is processing the question 0138\n",
      "OpenAIModel finished the question 0138 took 0.9482638835906982\n",
      "OpenAIModel is processing the question 0139\n",
      "OpenAIModel finished the question 0139 took 0.5883562564849854\n",
      "OpenAIModel is processing the question 0140\n",
      "OpenAIModel finished the question 0140 took 0.6097269058227539\n",
      "OpenAIModel is processing the question 0141\n",
      "OpenAIModel finished the question 0141 took 3.916661024093628\n",
      "OpenAIModel is processing the question 0142\n",
      "OpenAIModel finished the question 0142 took 0.7258410453796387\n",
      "OpenAIModel is processing the question 0143\n",
      "OpenAIModel finished the question 0143 took 0.8146300315856934\n",
      "OpenAIModel is processing the question 0144\n",
      "OpenAIModel finished the question 0144 took 0.7449789047241211\n",
      "OpenAIModel is processing the question 0145\n",
      "OpenAIModel finished the question 0145 took 0.7306029796600342\n",
      "OpenAIModel is processing the question 0146\n",
      "OpenAIModel finished the question 0146 took 0.7352221012115479\n",
      "OpenAIModel is processing the question 0147\n",
      "OpenAIModel finished the question 0147 took 0.5715599060058594\n",
      "OpenAIModel is processing the question 0148\n",
      "OpenAIModel finished the question 0148 took 1.004892110824585\n",
      "OpenAIModel is processing the question 0149\n",
      "OpenAIModel finished the question 0149 took 3.256486177444458\n",
      "OpenAIModel is processing the question 0150\n",
      "OpenAIModel finished the question 0150 took 0.6468379497528076\n",
      "OpenAIModel is processing the question 0151\n",
      "OpenAIModel finished the question 0151 took 0.8309578895568848\n",
      "OpenAIModel is processing the question 0152\n",
      "OpenAIModel finished the question 0152 took 0.5696613788604736\n",
      "OpenAIModel is processing the question 0153\n",
      "OpenAIModel finished the question 0153 took 0.7879238128662109\n",
      "OpenAIModel is processing the question 0154\n",
      "OpenAIModel finished the question 0154 took 0.7331399917602539\n",
      "OpenAIModel is processing the question 0155\n",
      "OpenAIModel finished the question 0155 took 0.6631109714508057\n",
      "OpenAIModel is processing the question 0156\n",
      "OpenAIModel finished the question 0156 took 0.5719733238220215\n",
      "OpenAIModel is processing the question 0157\n",
      "OpenAIModel finished the question 0157 took 1.8747248649597168\n",
      "OpenAIModel is processing the question 0158\n",
      "OpenAIModel finished the question 0158 took 0.5789549350738525\n",
      "OpenAIModel is processing the question 0159\n",
      "OpenAIModel finished the question 0159 took 0.782170295715332\n",
      "OpenAIModel is processing the question 0160\n",
      "OpenAIModel finished the question 0160 took 3.328346014022827\n",
      "OpenAIModel is processing the question 0161\n",
      "OpenAIModel finished the question 0161 took 3.5586130619049072\n",
      "OpenAIModel is processing the question 0162\n",
      "OpenAIModel finished the question 0162 took 0.597649097442627\n",
      "OpenAIModel is processing the question 0163\n",
      "OpenAIModel finished the question 0163 took 0.6579270362854004\n",
      "OpenAIModel is processing the question 0164\n",
      "OpenAIModel finished the question 0164 took 1.3463261127471924\n",
      "OpenAIModel is processing the question 0165\n",
      "OpenAIModel finished the question 0165 took 0.828549861907959\n",
      "OpenAIModel is processing the question 0166\n",
      "OpenAIModel finished the question 0166 took 0.9323949813842773\n",
      "OpenAIModel is processing the question 0167\n",
      "OpenAIModel finished the question 0167 took 0.8445920944213867\n",
      "OpenAIModel is processing the question 0168\n",
      "OpenAIModel finished the question 0168 took 1.546821117401123\n",
      "OpenAIModel is processing the question 0169\n",
      "OpenAIModel finished the question 0169 took 0.6210212707519531\n",
      "OpenAIModel is processing the question 0170\n",
      "OpenAIModel finished the question 0170 took 0.9338870048522949\n",
      "OpenAIModel is processing the question 0171\n",
      "OpenAIModel finished the question 0171 took 1.5531680583953857\n",
      "OpenAIModel is processing the question 0172\n",
      "OpenAIModel finished the question 0172 took 0.7339730262756348\n",
      "OpenAIModel is processing the question 0173\n",
      "OpenAIModel finished the question 0173 took 1.138495922088623\n",
      "OpenAIModel is processing the question 0174\n",
      "OpenAIModel finished the question 0174 took 0.5748882293701172\n",
      "OpenAIModel is processing the question 0175\n",
      "OpenAIModel finished the question 0175 took 1.935811996459961\n",
      "OpenAIModel is processing the question 0176\n",
      "OpenAIModel finished the question 0176 took 0.7280189990997314\n",
      "OpenAIModel is processing the question 0177\n",
      "OpenAIModel finished the question 0177 took 0.5388779640197754\n",
      "OpenAIModel is processing the question 0178\n",
      "OpenAIModel finished the question 0178 took 0.8485000133514404\n",
      "OpenAIModel is processing the question 0179\n",
      "OpenAIModel finished the question 0179 took 0.6840617656707764\n",
      "OpenAIModel is processing the question 0180\n",
      "OpenAIModel finished the question 0180 took 3.9348340034484863\n",
      "OpenAIModel is processing the question 0181\n",
      "OpenAIModel finished the question 0181 took 0.7086730003356934\n",
      "OpenAIModel is processing the question 0182\n",
      "OpenAIModel finished the question 0182 took 0.8968219757080078\n",
      "OpenAIModel is processing the question 0183\n",
      "OpenAIModel finished the question 0183 took 0.6654472351074219\n",
      "OpenAIModel is processing the question 0184\n",
      "OpenAIModel finished the question 0184 took 0.6298947334289551\n",
      "OpenAIModel is processing the question 0185\n",
      "OpenAIModel finished the question 0185 took 2.0597140789031982\n",
      "OpenAIModel is processing the question 0186\n",
      "OpenAIModel finished the question 0186 took 0.732865571975708\n",
      "OpenAIModel is processing the question 0187\n",
      "OpenAIModel finished the question 0187 took 0.6179201602935791\n",
      "OpenAIModel is processing the question 0188\n",
      "OpenAIModel finished the question 0188 took 0.5468380451202393\n",
      "OpenAIModel is processing the question 0189\n",
      "OpenAIModel finished the question 0189 took 0.5318231582641602\n",
      "OpenAIModel is processing the question 0190\n",
      "OpenAIModel finished the question 0190 took 0.5654749870300293\n",
      "OpenAIModel is processing the question 0191\n",
      "OpenAIModel finished the question 0191 took 0.8736100196838379\n",
      "OpenAIModel is processing the question 0192\n",
      "OpenAIModel finished the question 0192 took 0.7227787971496582\n",
      "OpenAIModel is processing the question 0193\n",
      "OpenAIModel finished the question 0193 took 0.6693291664123535\n",
      "OpenAIModel is processing the question 0194\n",
      "OpenAIModel finished the question 0194 took 0.5861377716064453\n",
      "OpenAIModel is processing the question 0195\n",
      "OpenAIModel finished the question 0195 took 0.8333261013031006\n",
      "OpenAIModel is processing the question 0196\n",
      "OpenAIModel finished the question 0196 took 3.088927984237671\n",
      "OpenAIModel is processing the question 0197\n",
      "OpenAIModel finished the question 0197 took 0.5654251575469971\n",
      "OpenAIModel is processing the question 0198\n",
      "OpenAIModel finished the question 0198 took 0.6795415878295898\n",
      "OpenAIModel is processing the question 0199\n",
      "OpenAIModel finished the question 0199 took 1.0352749824523926\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/data/LaMP_11_dev_preds_OpenAI.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./src/data/LaMP_11_dev_prompts_with_keyword.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m task_1_train_with_keyword(prompt_file_path)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtask_1_train_with_keyword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(task_1_train_with_keyword\u001b[38;5;241m.\u001b[39mscore)\n",
      "File \u001b[0;32m~/Desktop/COMPSCI646/LaMP-Retreival/src/task.py:109\u001b[0m, in \u001b[0;36mLaMPTask.evaluate\u001b[0;34m(self, preds_save_name)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     curr_preds_save_name \u001b[38;5;241m=\u001b[39m preds_save_name[index]\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore[subscriber_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurr_preds_save_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_name\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/COMPSCI646/LaMP-Retreival/src/evaluation.py:180\u001b[0m, in \u001b[0;36mLaMPEvaluation.evaluate_task\u001b[0;34m(self, predicts_json_addr, task_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, predicts_json_addr, task_name):\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredicts_json_addr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    181\u001b[0m         preds \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    183\u001b[0m         preds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m task_name\n\u001b[1;32m    184\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided task_name and the results do not match.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/data/LaMP_11_dev_preds_OpenAI.json'"
     ]
    }
   ],
   "source": [
    "prompt_file_path = \"./src/data/LaMP_11_dev_prompts_with_keyword.json\"\n",
    "task_1_train_with_keyword(prompt_file_path)\n",
    "task_1_train_with_keyword.evaluate()\n",
    "print(task_1_train_with_keyword.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import json\n",
    "from src.utils.dto import DTOEncoder\n",
    "\n",
    "with open(\".tmp.json\", \"w\", encoding=\"utf-8\") as tmp:\n",
    "    json.dump(task_1_train_with_keyword.preds, tmp, indent=4, cls=DTOEncoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:33:25.345203Z",
     "start_time": "2023-11-30T22:33:25.339442Z"
    }
   },
   "id": "c957b6d82d97ec7a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b67a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"BERTSERINI\": {\n",
      "        \"accuracy\": 0.6,\n",
      "        \"f1\": 0.37499999999999994\n",
      "    },\n",
      "    \"DistilBERT\": {\n",
      "        \"accuracy\": 0.6,\n",
      "        \"f1\": 0.37499999999999994\n",
      "    },\n",
      "    \"MiniLM\": {\n",
      "        \"accuracy\": 0.6,\n",
      "        \"f1\": 0.5833333333333333\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "print(json.dumps(task_1_train_with_keyword.score, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd4813b9a2f155a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T16:23:58.037810Z",
     "start_time": "2023-12-01T16:13:42.847946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIModel is processing the questions\n",
      "OpenAIModel is processing the question 010\n",
      "OpenAIModel finished the question 010 took 0.7147247791290283\n",
      "OpenAIModel is processing the question 011\n",
      "OpenAIModel finished the question 011 took 2.6095011234283447\n",
      "OpenAIModel is processing the question 012\n",
      "OpenAIModel finished the question 012 took 0.6738910675048828\n",
      "OpenAIModel is processing the question 013\n",
      "OpenAIModel finished the question 013 took 0.7782928943634033\n",
      "OpenAIModel is processing the question 014\n",
      "OpenAIModel finished the question 014 took 1.1004359722137451\n",
      "OpenAIModel is processing the question 015\n",
      "OpenAIModel finished the question 015 took 0.7572300434112549\n",
      "OpenAIModel is processing the question 016\n",
      "OpenAIModel finished the question 016 took 0.7353909015655518\n",
      "OpenAIModel is processing the question 017\n",
      "OpenAIModel finished the question 017 took 0.7291338443756104\n",
      "OpenAIModel is processing the question 018\n",
      "OpenAIModel finished the question 018 took 0.8306012153625488\n",
      "OpenAIModel is processing the question 019\n",
      "OpenAIModel finished the question 019 took 0.7280380725860596\n",
      "OpenAIModel is processing the question 0110\n",
      "OpenAIModel finished the question 0110 took 0.6079721450805664\n",
      "OpenAIModel is processing the question 0111\n",
      "OpenAIModel finished the question 0111 took 0.668989896774292\n",
      "OpenAIModel is processing the question 0112\n",
      "OpenAIModel finished the question 0112 took 0.6104559898376465\n",
      "OpenAIModel is processing the question 0113\n",
      "OpenAIModel finished the question 0113 took 0.9368729591369629\n",
      "OpenAIModel is processing the question 0114\n",
      "OpenAIModel finished the question 0114 took 0.7284419536590576\n",
      "OpenAIModel is processing the question 0115\n",
      "OpenAIModel finished the question 0115 took 0.5996990203857422\n",
      "OpenAIModel is processing the question 0116\n",
      "OpenAIModel finished the question 0116 took 0.6441867351531982\n",
      "OpenAIModel is processing the question 0117\n",
      "OpenAIModel finished the question 0117 took 0.8420672416687012\n",
      "OpenAIModel is processing the question 0118\n",
      "OpenAIModel finished the question 0118 took 2.16465425491333\n",
      "OpenAIModel is processing the question 0119\n",
      "OpenAIModel finished the question 0119 took 2.7741823196411133\n",
      "OpenAIModel is processing the question 0120\n",
      "OpenAIModel finished the question 0120 took 0.7315871715545654\n",
      "OpenAIModel is processing the question 0121\n",
      "OpenAIModel finished the question 0121 took 0.678704023361206\n",
      "OpenAIModel is processing the question 0122\n",
      "OpenAIModel finished the question 0122 took 2.5291390419006348\n",
      "OpenAIModel is processing the question 0123\n",
      "OpenAIModel finished the question 0123 took 3.1352739334106445\n",
      "OpenAIModel is processing the question 0124\n",
      "OpenAIModel finished the question 0124 took 1.0882418155670166\n",
      "OpenAIModel is processing the question 0125\n",
      "OpenAIModel finished the question 0125 took 1.1085779666900635\n",
      "OpenAIModel is processing the question 0126\n",
      "OpenAIModel finished the question 0126 took 0.8619592189788818\n",
      "OpenAIModel is processing the question 0127\n",
      "OpenAIModel finished the question 0127 took 4.835586071014404\n",
      "OpenAIModel is processing the question 0128\n",
      "OpenAIModel finished the question 0128 took 0.8218600749969482\n",
      "OpenAIModel is processing the question 0129\n",
      "OpenAIModel finished the question 0129 took 1.7542741298675537\n",
      "OpenAIModel is processing the question 0130\n",
      "OpenAIModel finished the question 0130 took 0.49757814407348633\n",
      "OpenAIModel is processing the question 0131\n",
      "OpenAIModel finished the question 0131 took 0.7619688510894775\n",
      "OpenAIModel is processing the question 0132\n",
      "OpenAIModel finished the question 0132 took 1.9775240421295166\n",
      "OpenAIModel is processing the question 0133\n",
      "OpenAIModel finished the question 0133 took 0.6889970302581787\n",
      "OpenAIModel is processing the question 0134\n",
      "OpenAIModel finished the question 0134 took 0.7533938884735107\n",
      "OpenAIModel is processing the question 0135\n",
      "OpenAIModel finished the question 0135 took 0.7317171096801758\n",
      "OpenAIModel is processing the question 0136\n",
      "OpenAIModel finished the question 0136 took 3.0217411518096924\n",
      "OpenAIModel is processing the question 0137\n",
      "OpenAIModel finished the question 0137 took 0.7867541313171387\n",
      "OpenAIModel is processing the question 0138\n",
      "OpenAIModel finished the question 0138 took 0.7311587333679199\n",
      "OpenAIModel is processing the question 0139\n",
      "OpenAIModel finished the question 0139 took 0.7368881702423096\n",
      "OpenAIModel is processing the question 0140\n",
      "OpenAIModel finished the question 0140 took 0.7293398380279541\n",
      "OpenAIModel is processing the question 0141\n",
      "OpenAIModel finished the question 0141 took 1.4796030521392822\n",
      "OpenAIModel is processing the question 0142\n",
      "OpenAIModel finished the question 0142 took 2.027215003967285\n",
      "OpenAIModel is processing the question 0143\n",
      "OpenAIModel finished the question 0143 took 1.7076239585876465\n",
      "OpenAIModel is processing the question 0144\n",
      "OpenAIModel finished the question 0144 took 1.184520959854126\n",
      "OpenAIModel is processing the question 0145\n",
      "OpenAIModel finished the question 0145 took 0.675257682800293\n",
      "OpenAIModel is processing the question 0146\n",
      "OpenAIModel finished the question 0146 took 1.160750150680542\n",
      "OpenAIModel is processing the question 0147\n",
      "OpenAIModel finished the question 0147 took 0.8647370338439941\n",
      "OpenAIModel is processing the question 0148\n",
      "OpenAIModel finished the question 0148 took 0.7315840721130371\n",
      "OpenAIModel is processing the question 0149\n",
      "OpenAIModel finished the question 0149 took 1.8570168018341064\n",
      "OpenAIModel is processing the question 0150\n",
      "OpenAIModel finished the question 0150 took 1.1309618949890137\n",
      "OpenAIModel is processing the question 0151\n",
      "OpenAIModel finished the question 0151 took 0.8396680355072021\n",
      "OpenAIModel is processing the question 0152\n",
      "OpenAIModel finished the question 0152 took 0.7290830612182617\n",
      "OpenAIModel is processing the question 0153\n",
      "OpenAIModel finished the question 0153 took 1.2202348709106445\n",
      "OpenAIModel is processing the question 0154\n",
      "OpenAIModel finished the question 0154 took 0.6551601886749268\n",
      "OpenAIModel is processing the question 0155\n",
      "OpenAIModel finished the question 0155 took 0.613929033279419\n",
      "OpenAIModel is processing the question 0156\n",
      "OpenAIModel finished the question 0156 took 0.733557939529419\n",
      "OpenAIModel is processing the question 0157\n",
      "OpenAIModel finished the question 0157 took 0.6043150424957275\n",
      "OpenAIModel is processing the question 0158\n",
      "OpenAIModel finished the question 0158 took 1.4117109775543213\n",
      "OpenAIModel is processing the question 0159\n",
      "OpenAIModel finished the question 0159 took 0.720513105392456\n",
      "OpenAIModel is processing the question 0160\n",
      "OpenAIModel finished the question 0160 took 0.9127852916717529\n",
      "OpenAIModel is processing the question 0161\n",
      "OpenAIModel finished the question 0161 took 4.603811025619507\n",
      "OpenAIModel is processing the question 0162\n",
      "OpenAIModel finished the question 0162 took 0.7301681041717529\n",
      "OpenAIModel is processing the question 0163\n",
      "OpenAIModel finished the question 0163 took 0.6937460899353027\n",
      "OpenAIModel is processing the question 0164\n",
      "OpenAIModel finished the question 0164 took 0.640916109085083\n",
      "OpenAIModel is processing the question 0165\n",
      "OpenAIModel finished the question 0165 took 0.5962817668914795\n",
      "OpenAIModel is processing the question 0166\n",
      "OpenAIModel finished the question 0166 took 4.063551187515259\n",
      "OpenAIModel is processing the question 0167\n",
      "OpenAIModel finished the question 0167 took 1.0150840282440186\n",
      "OpenAIModel is processing the question 0168\n",
      "OpenAIModel finished the question 0168 took 0.6863560676574707\n",
      "OpenAIModel is processing the question 0169\n",
      "OpenAIModel finished the question 0169 took 0.9893467426300049\n",
      "OpenAIModel is processing the question 0170\n",
      "OpenAIModel finished the question 0170 took 0.5632870197296143\n",
      "OpenAIModel is processing the question 0171\n",
      "OpenAIModel finished the question 0171 took 0.7379887104034424\n",
      "OpenAIModel is processing the question 0172\n",
      "OpenAIModel finished the question 0172 took 0.5801029205322266\n",
      "OpenAIModel is processing the question 0173\n",
      "OpenAIModel finished the question 0173 took 0.6558160781860352\n",
      "OpenAIModel is processing the question 0174\n",
      "OpenAIModel finished the question 0174 took 2.4164528846740723\n",
      "OpenAIModel is processing the question 0175\n",
      "OpenAIModel finished the question 0175 took 0.5452051162719727\n",
      "OpenAIModel is processing the question 0176\n",
      "OpenAIModel finished the question 0176 took 0.7319440841674805\n",
      "OpenAIModel is processing the question 0177\n",
      "OpenAIModel finished the question 0177 took 0.7323510646820068\n",
      "OpenAIModel is processing the question 0178\n",
      "OpenAIModel finished the question 0178 took 0.5755879878997803\n",
      "OpenAIModel is processing the question 0179\n",
      "OpenAIModel finished the question 0179 took 0.7850492000579834\n",
      "OpenAIModel is processing the question 0180\n",
      "OpenAIModel finished the question 0180 took 0.5950360298156738\n",
      "OpenAIModel is processing the question 0181\n",
      "OpenAIModel finished the question 0181 took 0.9692058563232422\n",
      "OpenAIModel is processing the question 0182\n",
      "OpenAIModel finished the question 0182 took 0.7333800792694092\n",
      "OpenAIModel is processing the question 0183\n",
      "OpenAIModel finished the question 0183 took 0.7058188915252686\n",
      "OpenAIModel is processing the question 0184\n",
      "OpenAIModel finished the question 0184 took 0.6762261390686035\n",
      "OpenAIModel is processing the question 0185\n",
      "OpenAIModel finished the question 0185 took 0.6874618530273438\n",
      "OpenAIModel is processing the question 0186\n",
      "OpenAIModel finished the question 0186 took 0.6435139179229736\n",
      "OpenAIModel is processing the question 0187\n",
      "OpenAIModel finished the question 0187 took 0.8898601531982422\n",
      "OpenAIModel is processing the question 0188\n",
      "OpenAIModel finished the question 0188 took 0.7500081062316895\n",
      "OpenAIModel is processing the question 0189\n",
      "OpenAIModel finished the question 0189 took 0.6198687553405762\n",
      "OpenAIModel is processing the question 0190\n",
      "OpenAIModel finished the question 0190 took 0.829714298248291\n",
      "OpenAIModel is processing the question 0191\n",
      "OpenAIModel finished the question 0191 took 0.7310972213745117\n",
      "OpenAIModel is processing the question 0192\n",
      "OpenAIModel finished the question 0192 took 2.0709640979766846\n",
      "OpenAIModel is processing the question 0193\n",
      "OpenAIModel finished the question 0193 took 1.905090093612671\n",
      "OpenAIModel is processing the question 0194\n",
      "OpenAIModel finished the question 0194 took 1.7969729900360107\n",
      "OpenAIModel is processing the question 0195\n",
      "OpenAIModel finished the question 0195 took 2.6748359203338623\n",
      "OpenAIModel is processing the question 0196\n",
      "OpenAIModel finished the question 0196 took 0.6292619705200195\n",
      "OpenAIModel is processing the question 0197\n",
      "OpenAIModel finished the question 0197 took 0.6749579906463623\n",
      "OpenAIModel is processing the question 0198\n",
      "OpenAIModel finished the question 0198 took 1.8059399127960205\n",
      "OpenAIModel is processing the question 0199\n",
      "OpenAIModel finished the question 0199 took 1.0390050411224365\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/data/LaMP_11_dev_preds_OpenAI.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m prompt_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./src/data/LaMP_11_dev_prompts_without_keyword.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m task_1_train_without_keyword(prompt_file_path)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtask_1_train_without_keyword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(task_1_train_without_keyword\u001b[38;5;241m.\u001b[39mscore)\n",
      "File \u001b[0;32m~/Desktop/COMPSCI646/LaMP-Retreival/src/task.py:109\u001b[0m, in \u001b[0;36mLaMPTask.evaluate\u001b[0;34m(self, preds_save_name)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     curr_preds_save_name \u001b[38;5;241m=\u001b[39m preds_save_name[index]\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore[subscriber_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurr_preds_save_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_name\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/COMPSCI646/LaMP-Retreival/src/evaluation.py:180\u001b[0m, in \u001b[0;36mLaMPEvaluation.evaluate_task\u001b[0;34m(self, predicts_json_addr, task_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_task\u001b[39m(\u001b[38;5;28mself\u001b[39m, predicts_json_addr, task_name):\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredicts_json_addr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    181\u001b[0m         preds \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    183\u001b[0m         preds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m task_name\n\u001b[1;32m    184\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided task_name and the results do not match.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/data/LaMP_11_dev_preds_OpenAI.json'"
     ]
    }
   ],
   "source": [
    "task_1_train_without_keyword = LaMPTask(\n",
    "    \"./src/data/LaMP_11_dev_questions.json\",\n",
    "    \"./src/data/LaMP_11_dev_outputs.json\",\n",
    "    # \"./src/data/LaMP_11_dev_questions.json\",\n",
    "    # \"./src/data/LaMP_11_dev_outputs.json\",\n",
    "    subscribers={\n",
    "        # \"BERTSERINI\": BERTSERINI_Subscriber,\n",
    "        # \"DistilBERT\": DistilBERT_Subscriber,\n",
    "        # \"MiniLM\": MiniLM_Subscriber,\n",
    "        \"OpenAI\": OpenAI_Subscriber,\n",
    "    },\n",
    "    # subscribers={},\n",
    "    prompt_save_path=default_data_path,\n",
    "    keyword_extraction=False,\n",
    ")\n",
    "prompt_file_path = \"./src/data/LaMP_11_dev_prompts_without_keyword.json\"\n",
    "task_1_train_without_keyword(prompt_file_path)\n",
    "task_1_train_without_keyword.evaluate()\n",
    "print(task_1_train_without_keyword.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3573f9c5823caffa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:14:07.469656Z",
     "start_time": "2023-12-01T20:14:02.492327Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.evaluation import LaMPEvaluation\n",
    "from src.utils.func import extract_prompt_tokens_stats, extract_output_tokens_stats\n",
    "\n",
    "LaMPEvaluation_100 = LaMPEvaluation(\n",
    "    single_gold_json_file_addr=\"./src/data/LaMP_11_dev_outputs.json\"\n",
    ")\n",
    "LaMPEvaluation_250 = LaMPEvaluation(\n",
    "    single_gold_json_file_addr=\"./src/data/LaMP_12_dev_outputs.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "prompt_with_keyword_path_100 = \"./src/data/LaMP_11_dev_prompts_with_keyword.json\"\n",
    "prompt_without_keyword_path_100 = \"./src/data/LaMP_11_dev_prompts_without_keyword.json\"\n",
    "prompt_with_keyword_path_250 = \"./src/data/LaMP_12_dev_prompts_with_keyword.json\"\n",
    "prompt_without_keyword_path_250 = \"./src/data/LaMP_12_dev_prompts_without_keyword.json\"\n",
    "GPT_pred_path_with_keyword = \"./src/data/LaMP_11_dev_preds_OpenAI_with_keyword.json\"\n",
    "GPT_pred_path_without_keyword = (\n",
    "    \"./src/data/LaMP_11_dev_preds_OpenAI_without_keyword.json\"\n",
    ")\n",
    "BERTSERINIM_pred_path_with_keyword = (\n",
    "    \"./src/data/LaMP_12_dev_preds_BERTSERINI_with_keyword.json\"\n",
    ")\n",
    "BERTSERINIM_pred_path_without_keyword = (\n",
    "    \"./src/data/LaMP_12_dev_preds_BERTSERINI_without_keyword.json\"\n",
    ")\n",
    "DistilBERT_pred_path_with_keyword = (\n",
    "    \"./src/data/LaMP_12_dev_preds_DistilBERT_with_keyword.json\"\n",
    ")\n",
    "DistilBERT_pred_path_without_keyword = (\n",
    "    \"./src/data/LaMP_12_dev_preds_DistilBERT_without_keyword.json\"\n",
    ")\n",
    "MiniLM_pred_path_with_keyword = \"./src/data/LaMP_12_dev_preds_MiniLM_with_keyword.json\"\n",
    "MiniLM_pred_path_without_keyword = (\n",
    "    \"./src/data/LaMP_12_dev_preds_MiniLM_without_keyword.json\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:23:21.363347Z",
     "start_time": "2023-12-01T20:23:21.354322Z"
    }
   },
   "id": "7a21eb19f3deb5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def print_out_evaluation_info(\n",
    "    model_name: str,\n",
    "    pred_path: str,\n",
    "    prompts_path: str,\n",
    "    keyword_extraction: bool,\n",
    "    task: str,\n",
    "    evaluation: LaMPEvaluation,\n",
    "    cost: float = 0.0,\n",
    "):\n",
    "    suffix = \"with keyword\" if keyword_extraction else \"without keyword\"\n",
    "    evaluation = evaluation.evaluate_task(pred_path, task)\n",
    "    accuracy = evaluation[\"accuracy\"]\n",
    "    f1 = evaluation[\"f1\"]\n",
    "    print(f\"{model_name} {suffix} extraction:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"f1: {f1}\")\n",
    "    total_tokens, average_tokens, GPT_est_cost = extract_prompt_tokens_stats(\n",
    "        prompts_path, cost\n",
    "    )\n",
    "    print(f\"total tokens in json :{total_tokens}\")\n",
    "    print(f\"average tokens in each request: {average_tokens}\")\n",
    "    print(f\"estimate price to finsh this task {suffix} extraction: {GPT_est_cost}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:18:01.548821Z",
     "start_time": "2023-12-01T20:18:01.525227Z"
    }
   },
   "id": "421dc15665ff7bac"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 3.5 with turbo with keyword extraction:\n",
      "Accuracy: 0.48\n",
      "f1: 0.47481572481572476\n",
      "total tokens in json :17021\n",
      "average tokens in each request: 170.21\n",
      "estimate price to finsh this task with keyword extraction: 0.02\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"GPT 3.5 with turbo\",\n",
    "    GPT_pred_path_with_keyword,\n",
    "    prompt_with_keyword_path_100,\n",
    "    True,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_100,\n",
    "    0.001,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:18:04.985384Z",
     "start_time": "2023-12-01T20:18:03.858244Z"
    }
   },
   "id": "b8f58b945f0fb26"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 3.5 with turbo without keyword extraction:\n",
      "Accuracy: 0.45\n",
      "f1: 0.46340425531914897\n",
      "total tokens in json :97699\n",
      "average tokens in each request: 976.99\n",
      "estimate price to finsh this task without keyword extraction: 0.1\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"GPT 3.5 with turbo\",\n",
    "    GPT_pred_path_without_keyword,\n",
    "    prompt_without_keyword_path_100,\n",
    "    False,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_100,\n",
    "    0.001,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:18:29.922129Z",
     "start_time": "2023-12-01T20:18:28.784890Z"
    }
   },
   "id": "4736850d71c939fa"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ba51e313709787b8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTSERINI with keyword extraction:\n",
      "Accuracy: 0.54\n",
      "f1: 0.4062404870624049\n",
      "total tokens in json :42663\n",
      "average tokens in each request: 170.652\n",
      "estimate price to finsh this task with keyword extraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"BERTSERINI\",\n",
    "    BERTSERINIM_pred_path_with_keyword,\n",
    "    prompt_with_keyword_path_250,\n",
    "    True,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_250,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:21:16.711482Z",
     "start_time": "2023-12-01T20:21:15.482653Z"
    }
   },
   "id": "905642ef19cb883b"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTSERINI without keyword extraction:\n",
      "Accuracy: 0.432\n",
      "f1: 0.38764596212344216\n",
      "total tokens in json :226317\n",
      "average tokens in each request: 905.268\n",
      "estimate price to finsh this task without keyword extraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"BERTSERINI\",\n",
    "    BERTSERINIM_pred_path_without_keyword,\n",
    "    prompt_without_keyword_path_250,\n",
    "    False,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_250,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:21:32.248040Z",
     "start_time": "2023-12-01T20:21:31.125812Z"
    }
   },
   "id": "11eb32c67a9b74ee"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT with keyword extraction:\n",
      "Accuracy: 0.548\n",
      "f1: 0.3640199552405819\n",
      "total tokens in json :42663\n",
      "average tokens in each request: 170.652\n",
      "estimate price to finsh this task with keyword extraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"DistilBERT\",\n",
    "    DistilBERT_pred_path_with_keyword,\n",
    "    prompt_with_keyword_path_250,\n",
    "    True,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_250,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:22:12.139824Z",
     "start_time": "2023-12-01T20:22:11.016941Z"
    }
   },
   "id": "e1addb237679bcfb"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT without keyword extraction:\n",
      "Accuracy: 0.456\n",
      "f1: 0.40010351966873714\n",
      "total tokens in json :226317\n",
      "average tokens in each request: 905.268\n",
      "estimate price to finsh this task without keyword extraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"DistilBERT\",\n",
    "    DistilBERT_pred_path_without_keyword,\n",
    "    prompt_without_keyword_path_250,\n",
    "    False,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_250,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:22:38.839604Z",
     "start_time": "2023-12-01T20:22:37.658209Z"
    }
   },
   "id": "133140f7da01f3c6"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniLM with keyword extraction:\n",
      "Accuracy: 0.644\n",
      "f1: 0.6414702138287758\n",
      "total tokens in json :42663\n",
      "average tokens in each request: 170.652\n",
      "estimate price to finsh this task with keyword extraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"MiniLM\",\n",
    "    MiniLM_pred_path_with_keyword,\n",
    "    prompt_with_keyword_path_250,\n",
    "    True,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_250,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:23:28.461069Z",
     "start_time": "2023-12-01T20:23:27.381174Z"
    }
   },
   "id": "9bb4938ed552799b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniLM without keyword extraction:\n",
      "Accuracy: 0.648\n",
      "f1: 0.6491107847936042\n",
      "total tokens in json :226317\n",
      "average tokens in each request: 905.268\n",
      "estimate price to finsh this task without keyword extraction: 0.0\n"
     ]
    }
   ],
   "source": [
    "print_out_evaluation_info(\n",
    "    \"MiniLM\",\n",
    "    MiniLM_pred_path_without_keyword,\n",
    "    prompt_without_keyword_path_250,\n",
    "    False,\n",
    "    \"LaMP_1\",\n",
    "    LaMPEvaluation_250,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T20:24:24.992115Z",
     "start_time": "2023-12-01T20:24:23.610980Z"
    }
   },
   "id": "576b29d6adc95994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "477104fac45f1e49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('LaMP-RM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0dc0b78bb79ceedacc4b28a7c7a95f5c8ff7649848bf08868c2ee4cc7d3ac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
