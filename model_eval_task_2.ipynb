{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864b447a2f210f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T18:10:35.774248Z",
     "start_time": "2023-11-30T18:10:30.831190Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Dict, Tuple\n",
    "from typing import List\n",
    "from src.utils import default_data_path, config_to_env, check_config\n",
    "from src.task import LaMPTask\n",
    "from src.models import (\n",
    "    feed_prompt_to_lm,\n",
    "    feed_prompts_to_lm,\n",
    "    OpenAIModel,\n",
    "    task_2_parse_response,\n",
    "    DistilBERTModel,\n",
    "    BERTSERINIModel,\n",
    "    MiniLM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dec76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T18:10:35.803973Z",
     "start_time": "2023-11-30T18:10:35.778767Z"
    }
   },
   "outputs": [],
   "source": [
    "config_to_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ce4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_header = \"LaMP_2\"\n",
    "store_folder = os.path.join(\"src\", \"data\", task_header)\n",
    "\n",
    "OpenAI_Subscriber = lambda id, prompt, api_key: feed_prompt_to_lm(\n",
    "    model=OpenAIModel(),\n",
    "    id=id,\n",
    "    prompt=prompt,\n",
    "    api_key=api_key,\n",
    "    log_path=os.path.join(store_folder, \"OpenAI.txt\"),\n",
    "    callback=task_2_parse_response,\n",
    ")\n",
    "DistilBERT_Subscriber = lambda id, prompt, api_key: feed_prompt_to_lm(\n",
    "    model=DistilBERTModel(task_name=\"LaMP_2\"),\n",
    "    id=id,\n",
    "    prompt=prompt,\n",
    "    api_key=api_key,\n",
    "    log_path=os.path.join(store_folder, \"DistilBERTModel.txt\"),\n",
    "    callback=task_2_parse_response,\n",
    ")\n",
    "BERTSERINI_Subscriber = lambda id, prompt, api_key: feed_prompt_to_lm(\n",
    "    model=BERTSERINIModel(task_name=\"LaMP_2\"),\n",
    "    id=id,\n",
    "    prompt=prompt,\n",
    "    api_key=api_key,\n",
    "    log_path=os.path.join(store_folder, \"BERTSERINI.txt\"),\n",
    "    callback=task_2_parse_response,\n",
    ")\n",
    "MiniLM_Subscriber = lambda id, prompt, api_key: feed_prompt_to_lm(\n",
    "    model=MiniLM(task_name=\"LaMP_2\"),\n",
    "    id=id,\n",
    "    prompt=prompt,\n",
    "    api_key=api_key,\n",
    "    log_path=os.path.join(store_folder, \"MiniLM.txt\"),\n",
    "    callback=task_2_parse_response,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d0a3c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_header' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m store_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, task_header)\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(store_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m subscribers_full \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTSERINI\u001b[39m\u001b[38;5;124m\"\u001b[39m: BERTSERINI_Subscriber,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistilBERT\u001b[39m\u001b[38;5;124m\"\u001b[39m: DistilBERT_Subscriber,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMiniLM\u001b[39m\u001b[38;5;124m\"\u001b[39m: MiniLM_Subscriber,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m: OpenAI_Subscriber,\n\u001b[0;32m      8\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'task_header' is not defined"
     ]
    }
   ],
   "source": [
    "store_dir = os.path.join(\"src\", \"data\", task_header)\n",
    "os.makedirs(store_dir, exist_ok=True)\n",
    "subscribers_full = {\n",
    "    \"BERTSERINI\": BERTSERINI_Subscriber,\n",
    "    \"DistilBERT\": DistilBERT_Subscriber,\n",
    "    \"MiniLM\": MiniLM_Subscriber,\n",
    "    \"OpenAI\": OpenAI_Subscriber,\n",
    "}\n",
    "preds_save_path_full = {\n",
    "    \"BERTSERINI\": os.path.join(\n",
    "        store_dir,\n",
    "        f\"{task_header}_train_preds_BERTSERINI_with_keyword_{{file_ending}}.json\",\n",
    "    ),\n",
    "    \"DistilBERT\": os.path.join(\n",
    "        store_dir,\n",
    "        f\"{task_header}_train_preds_DistilBERT_with_keyword_{{file_ending}}.json\",\n",
    "    ),\n",
    "    \"MiniLM\": os.path.join(\n",
    "        store_dir,\n",
    "        f\"{task_header}_train_preds_MiniLM_with_keyword_{{file_ending}}.json\",\n",
    "    ),\n",
    "    \"OpenAI\": os.path.join(\n",
    "        store_dir, f\"{task_header}_train_preds_OpenAI_with_keyword_{{file_ending}}.json\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "task_header = \"LaMP_2\"\n",
    "entry_per_category = 16\n",
    "dataset_question_path = os.path.join(\"src\", \"data\", \"LaMP_2_train_questions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa06ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T18:10:37.680350Z",
     "start_time": "2023-11-30T18:10:35.787695Z"
    }
   },
   "outputs": [],
   "source": [
    "def task_2_with_keywords_query(\n",
    "    with_keyword_params, subscriber_namelist: List[str], debug: bool = False\n",
    "):\n",
    "    worker_count = 8 if not debug else 1\n",
    "    api_keys = (\n",
    "        [\n",
    "            check_config(\"HUGGING_FACE_KEY_1\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_2\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_3\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_4\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_1\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_2\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_3\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_4\"),\n",
    "        ]\n",
    "        if not debug\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    ready_model = dict()\n",
    "\n",
    "    for text_rank_top_k_keywords, category_top_k_keywords in with_keyword_params:\n",
    "        subscribers = dict()\n",
    "        preds_save_path = dict()\n",
    "        file_ending = (\n",
    "            f\"{entry_per_category}_{text_rank_top_k_keywords}_{category_top_k_keywords}\"\n",
    "        )\n",
    "\n",
    "        question_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_prompts_questions_with_keyword_{file_ending}.json\",\n",
    "        )\n",
    "        output_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_outputs_selected_with_keyword_{file_ending}.json\",\n",
    "        )\n",
    "\n",
    "        for subscriber_name in subscriber_namelist:\n",
    "            subscribers[subscriber_name] = subscribers_full[subscriber_name]\n",
    "            preds_save_path[subscriber_name] = preds_save_path_full[\n",
    "                subscriber_name\n",
    "            ].format(file_ending=file_ending)\n",
    "\n",
    "        curr_task = LaMPTask(\n",
    "            task_question_file=dataset_question_path,\n",
    "            task_output_file=output_store_path,\n",
    "            subscribers=subscribers,\n",
    "            worker_count=worker_count,\n",
    "            prompt_save_path=question_store_path,\n",
    "            preds_save_path=preds_save_path,\n",
    "            keyword_extraction=True,\n",
    "        )\n",
    "\n",
    "        ready_model[(text_rank_top_k_keywords, category_top_k_keywords)] = curr_task\n",
    "        curr_task.load_prompts(question_store_path)\n",
    "        curr_task.subscribe(\n",
    "            skip_eval=True,\n",
    "            api_keys=api_keys,\n",
    "        )\n",
    "\n",
    "\n",
    "def task_2_with_keywords_eval(\n",
    "    with_keyword_params,\n",
    "    subscriber_namelist: List[str],\n",
    "    ready_models: Dict[Tuple[int, int], LaMPTask] = None,\n",
    "):\n",
    "    if ready_models is not None:\n",
    "        for (\n",
    "            text_rank_top_k_keywords,\n",
    "            category_top_k_keywords,\n",
    "        ), curr_task in ready_models.items():\n",
    "            curr_task.evaluate()\n",
    "        return\n",
    "\n",
    "    store_dir = os.path.join(\"src\", \"data\", task_header)\n",
    "\n",
    "    evaluated_result = dict()\n",
    "\n",
    "    for text_rank_top_k_keywords, category_top_k_keywords in with_keyword_params:\n",
    "        subscribers = dict()\n",
    "        preds_save_path = dict()\n",
    "\n",
    "        for subscriber_name in subscriber_namelist:\n",
    "            subscribers[subscriber_name] = subscribers_full[subscriber_name]\n",
    "            preds_save_path[subscriber_name] = preds_save_path_full[\n",
    "                subscriber_name\n",
    "            ].format(file_ending=file_ending)\n",
    "\n",
    "        file_ending = (\n",
    "            f\"{entry_per_category}_{text_rank_top_k_keywords}_{category_top_k_keywords}\"\n",
    "        )\n",
    "        output_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_outputs_selected_with_keyword_{file_ending}.json\",\n",
    "        )\n",
    "        curr_task = LaMPTask(\n",
    "            task_question_file=dataset_question_path,\n",
    "            task_output_file=output_store_path,\n",
    "            subscribers=subscribers,\n",
    "        )\n",
    "        curr_task.evaluate(preds_save_name=preds_save_path)\n",
    "        print(curr_task.score)\n",
    "        evaluated_result[\n",
    "            f\"{text_rank_top_k_keywords} {category_top_k_keywords}\"\n",
    "        ] = curr_task.score\n",
    "    return evaluated_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30df99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_keyword_params = [(5, 15), (10, 30)]\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d07781",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_keyword_params = [(5, 15)]\n",
    "# with_keyword_params = [(10, 30)]\n",
    "# debug=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2126c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_models = task_2_with_keywords_query(with_keyword_params, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066da020",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_results = task_2_with_keywords_eval(with_keyword_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd44102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2_without_keywords_query(\n",
    "    without_keyword_params, subscriber_namelist: List[str], debug: bool = False\n",
    "):\n",
    "    worker_count = 8 if not debug else 1\n",
    "    api_keys = (\n",
    "        [\n",
    "            check_config(\"HUGGING_FACE_KEY_1\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_2\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_3\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_4\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_1\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_2\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_3\"),\n",
    "            check_config(\"HUGGING_FACE_KEY_4\"),\n",
    "        ]\n",
    "        if not debug\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    ready_model = dict()\n",
    "\n",
    "    for bm25_top_k in without_keyword_params:\n",
    "        subscribers = dict()\n",
    "        preds_save_path = dict()\n",
    "        file_ending = f\"{entry_per_category}_{bm25_top_k}\"\n",
    "\n",
    "        question_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_prompts_questions_without_keyword_{file_ending}.json\",\n",
    "        )\n",
    "        output_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_outputs_selected_without_keyword_{file_ending}.json\",\n",
    "        )\n",
    "\n",
    "        for subscriber_name in subscriber_namelist:\n",
    "            subscribers[subscriber_name] = subscribers_full[subscriber_name]\n",
    "            preds_save_path[subscriber_name] = preds_save_path_full[\n",
    "                subscriber_name\n",
    "            ].format(file_ending=file_ending)\n",
    "\n",
    "        curr_task = LaMPTask(\n",
    "            task_question_file=dataset_question_path,\n",
    "            task_output_file=output_store_path,\n",
    "            subscribers=subscribers,\n",
    "            worker_count=worker_count,\n",
    "            prompt_save_path=question_store_path,\n",
    "            preds_save_path=preds_save_path,\n",
    "            keyword_extraction=False,\n",
    "        )\n",
    "\n",
    "        ready_model[bm25_top_k] = curr_task\n",
    "        curr_task.load_prompts(question_store_path)\n",
    "        curr_task.subscribe(\n",
    "            skip_eval=True,\n",
    "            api_keys=api_keys,\n",
    "        )\n",
    "\n",
    "\n",
    "def task_2_without_keywords_eval(\n",
    "    without_keyword_params,\n",
    "    subscriber_namelist: List[str],\n",
    "    ready_models: Dict[Tuple[int, int], LaMPTask] = None,\n",
    "):\n",
    "    if ready_models is not None:\n",
    "        for bm25_top_k, curr_task in ready_models.items():\n",
    "            curr_task.evaluate()\n",
    "        return\n",
    "\n",
    "    evaluated_result = dict()\n",
    "\n",
    "    for bm25_top_k in without_keyword_params:\n",
    "        subscribers = dict()\n",
    "        preds_save_path = dict()\n",
    "        file_ending = f\"{entry_per_category}_{bm25_top_k}\"\n",
    "        output_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_outputs_selected_without_keyword_{file_ending}.json\",\n",
    "        )\n",
    "\n",
    "        for subscriber_name in subscriber_namelist:\n",
    "            subscribers[subscriber_name] = subscribers_full[subscriber_name]\n",
    "            preds_save_path[subscriber_name] = preds_save_path_full[\n",
    "                subscriber_name\n",
    "            ].format(file_ending=file_ending)\n",
    "\n",
    "        curr_task = LaMPTask(\n",
    "            task_question_file=dataset_question_path,\n",
    "            task_output_file=output_store_path,\n",
    "            subscribers=subscribers,\n",
    "        )\n",
    "        curr_task.evaluate(preds_save_name=preds_save_path)\n",
    "        print(curr_task.score)\n",
    "        evaluated_result[f\"{bm25_top_k}\"] = curr_task.score\n",
    "    return evaluated_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65114dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "without_keyword_params = [2, 4]\n",
    "without_keyword_params = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7136bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_models_no_keywords = task_2_without_keywords_query(\n",
    "    without_keyword_params, debug=debug\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13405aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_results_no_keywords = task_2_without_keywords_eval(without_keyword_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0dc0b78bb79ceedacc4b28a7c7a95f5c8ff7649848bf08868c2ee4cc7d3ac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
