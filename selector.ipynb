{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "from queue import Queue, Empty\n",
    "import random\n",
    "from threading import Event, Thread\n",
    "import time\n",
    "from typing import Callable, Dict, List\n",
    "from src.utils import labels, DTOEncoder, task_2_categories, default_data_path\n",
    "from src.extraction import extract_isntance_info_LaMP_2_alt\n",
    "from src.tokenization import lemma_tokenizer\n",
    "\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task_2_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.22-caliber'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "next(wn.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from threading import Lock\n",
    "from rich.progress import Progress, TaskID\n",
    "\n",
    "# prompt_dict: Dict[str, str] = dict()\n",
    "counter_lock = Lock()\n",
    "total = 0\n",
    "total_valid = 0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def LaMP_2_extract_func(\n",
    "    prompt_dict,\n",
    "    prog: Progress,\n",
    "    task: TaskID,\n",
    "    task_valid: TaskID,\n",
    "    id_list: List[str],\n",
    "    pipeline: Queue,\n",
    "    msg_pipe: Queue,\n",
    "):\n",
    "    global counter_lock, counter, total, total_valid\n",
    "    while True:\n",
    "        # try:\n",
    "        #     instance = pipeline.get_nowait()\n",
    "        #     if instance is None:\n",
    "        #         time.sleep(0.1)\n",
    "        #         continue\n",
    "        #     msg_pipe.put(instance[\"id\"])\n",
    "        instance: Dict[str, str] = pipeline.get()\n",
    "        if instance[\"id\"] == \"finished\":\n",
    "            break\n",
    "        if instance[\"id\"] in id_list:\n",
    "            # msg_pipe.put(f\"Skipping {instance['id']}...\")\n",
    "            # msg_pipe.put(f\"Processing {instance['id']}...\")\n",
    "            prompt_dict[instance[\"id\"]] = extract_isntance_info_LaMP_2_alt(\n",
    "                question=instance,\n",
    "                tokenizer=lemma_tokenizer,\n",
    "            )\n",
    "            prog.update(task_valid, advance=100 / total_valid)\n",
    "            # with counter_lock:\n",
    "            #     counter += 1\n",
    "        # msg_pipe.put(f\"Processed {instance['id']}...\")\n",
    "        prog.update(task, advance=100 / total)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     continue\n",
    "\n",
    "\n",
    "def selector(\n",
    "    dataset_question_path: str,\n",
    "    dataset_output_path: str,\n",
    "    entry_per_category: int = 5,\n",
    "    worker_count: int = 5,\n",
    "    with_keyword_extraction: bool = True,\n",
    "):\n",
    "    tag = \"with_keywords\" if with_keyword_extraction else \"without_keywords\"\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dataset_output_path, \"r\", encoding=\"utf-8\") as output:\n",
    "        tmp = json.load(output)\n",
    "        for label in tmp[\"golds\"]:\n",
    "            category_map[label[\"output\"]].append(label)\n",
    "\n",
    "    selected_labels = []\n",
    "    for category, doc_labels in category_map.items():\n",
    "        if len(doc_labels) <= entry_per_category:\n",
    "            selected_labels.extend(doc_labels)\n",
    "            continue\n",
    "        # elif category == \"business\":\n",
    "        #     continue\n",
    "        selected_labels.extend(\n",
    "            random.choices(category_map[category], k=entry_per_category)\n",
    "        )\n",
    "    selected_labels = labels(task=tmp[\"task\"], golds=selected_labels)\n",
    "    new_output_path = (\n",
    "        dataset_output_path.rstrip(\".json\") + f\"_{entry_per_category}_{tag}.json\"\n",
    "    )\n",
    "    with open(new_output_path, \"w\", encoding=\"utf-8\") as new_output:\n",
    "        json.dump(selected_labels, new_output, cls=DTOEncoder, indent=4)\n",
    "\n",
    "    _, dataset_id, dataset_type, *_ = dataset_question_path.split(\"_\")\n",
    "\n",
    "    new_question_path = os.path.join(\n",
    "        default_data_path,\n",
    "        f\"LaMP_{dataset_id}_{dataset_type}_prompts_{tag}_{entry_per_category}.json\",\n",
    "    )\n",
    "    global counter, total, total_valid\n",
    "    with Progress() as prog:\n",
    "        task = prog.add_task(\"Parse Prompts\", total=100)\n",
    "        task_2 = prog.add_task(\"Parse Prompts (Only Valid)\", total=100)\n",
    "        prompt_dict = dict()\n",
    "        with open(dataset_question_path, \"r\", encoding=\"utf-8\") as question:\n",
    "            with open(new_question_path, \"w\", encoding=\"utf-8\") as new_question:\n",
    "                threads: List[Thread] = []\n",
    "                instances_queue = Queue()\n",
    "                msgs_queue = Queue()\n",
    "                total = 0\n",
    "                total_valid = 0\n",
    "\n",
    "                selected_ids = [label.id for label in selected_labels.golds]\n",
    "                selected_ids = sorted(selected_ids, key=lambda x: int(x))\n",
    "                print(selected_ids)\n",
    "                total_valid = len(selected_ids)\n",
    "                for i in range(worker_count):\n",
    "                    curr_worker = Thread(\n",
    "                        target=LaMP_2_extract_func,\n",
    "                        args=(\n",
    "                            prompt_dict,\n",
    "                            prog,\n",
    "                            task,\n",
    "                            task_2,\n",
    "                            selected_ids,\n",
    "                            instances_queue,\n",
    "                            msgs_queue,\n",
    "                        ),\n",
    "                    )\n",
    "                    curr_worker.start()\n",
    "                    threads.append(curr_worker)\n",
    "                instances = json.load(question)\n",
    "                total = len(instances)\n",
    "                print(total, total_valid)\n",
    "                for instance in instances:\n",
    "                    instances_queue.put(instance)\n",
    "\n",
    "                for i in range(worker_count):\n",
    "                    instances_queue.put({\"id\": \"finished\"})\n",
    "                # while counter < total_valid:\n",
    "                # print(msgs_queue.get())\n",
    "                # continue\n",
    "                join_task = prog.add_task(\"Exiting Threads\", total=100)\n",
    "                [worker.join() for worker in threads]\n",
    "                prog.update(join_task, advance=100)\n",
    "                save_task = prog.add_task(\"Saving Prompts\", total=100)\n",
    "                json.dump(prompt_dict, new_question, indent=4)\n",
    "                prog.update(save_task, advance=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89bf53aea394d8fb4a5bb196da038e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">['10433', '101306', '101608', '101808', '102889', '102918', '103299', '103521', '103586', '104050', '104737', \n",
       "'104778', '104957', '105379', '105754']\n",
       "</pre>\n"
      ],
      "text/plain": [
       "['10433', '101306', '101608', '101808', '102889', '102918', '103299', '103521', '103586', '104050', '104737', \n",
       "'104778', '104957', '105379', '105754']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">5914 15\n",
       "</pre>\n"
      ],
      "text/plain": [
       "5914 15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selector(\n",
    "    dataset_question_path=\"./src/data/LaMP_2_train_questions.json\",\n",
    "    dataset_output_path=\"./src/data/LaMP_2_train_outputs.json\",\n",
    "    entry_per_category=1,\n",
    "    worker_count=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('LaMP-RM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0dc0b78bb79ceedacc4b28a7c7a95f5c8ff7649848bf08868c2ee4cc7d3ac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
