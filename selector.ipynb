{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "from queue import Queue, Empty\n",
    "import random\n",
    "from threading import Event, Thread\n",
    "import time\n",
    "from typing import Callable, Dict, List\n",
    "from src.utils import labels, DTOEncoder, task_2_categories, default_data_path\n",
    "from src.extraction import extract_instance_info_LaMP_2_alt, extract_instance_info_LaMP_2_alt_no_keyword\n",
    "from src.tokenization import lemma_tokenizer\n",
    "\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task_2_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.22-caliber'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "next(wn.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from threading import Lock\n",
    "from rich.progress import Progress, TaskID\n",
    "\n",
    "# prompt_dict: Dict[str, str] = dict()\n",
    "counter_lock = Lock()\n",
    "total = 0\n",
    "total_valid = 0\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def LaMP_2_extract_func(\n",
    "    prompt_dict,\n",
    "    prog: Progress,\n",
    "    task: TaskID,\n",
    "    task_valid: TaskID,\n",
    "    id_list: List[str],\n",
    "    pipeline: Queue,\n",
    "    msg_pipe: Queue,\n",
    "    with_keyword_extraction: bool = True\n",
    "):\n",
    "    global counter_lock, counter, total, total_valid\n",
    "    while True:\n",
    "        instance: Dict[str, str] = pipeline.get()\n",
    "        if instance[\"id\"] == \"finished\":\n",
    "            break\n",
    "        if instance[\"id\"] in id_list:\n",
    "            prompt_dict[instance[\"id\"]] = extract_instance_info_LaMP_2_alt(\n",
    "                question=instance,\n",
    "                tokenizer=lemma_tokenizer,\n",
    "                keyword_extraction = with_keyword_extraction,\n",
    "            )\n",
    "            prog.update(task_valid, advance=100 / total_valid)\n",
    "        prog.update(task, advance=100 / total)\n",
    "\n",
    "\n",
    "def selector(\n",
    "    dataset_question_path: str,\n",
    "    dataset_output_path: str,\n",
    "    entry_per_category: int = 5,\n",
    "    worker_count: int = 5,\n",
    "    with_keyword_extraction: bool = True,\n",
    "):\n",
    "    tag = \"with_keyword\" if with_keyword_extraction else \"without_keyword\"\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dataset_output_path, \"r\", encoding=\"utf-8\") as output:\n",
    "        tmp = json.load(output)\n",
    "        for label in tmp[\"golds\"]:\n",
    "            category_map[label[\"output\"]].append(label)\n",
    "\n",
    "    selected_labels = []\n",
    "    for category, doc_labels in category_map.items():\n",
    "        if len(doc_labels) <= entry_per_category:\n",
    "            selected_labels.extend(doc_labels)\n",
    "            continue\n",
    "        # elif category == \"business\":\n",
    "        #     continue\n",
    "        selected_labels.extend(\n",
    "            random.choices(category_map[category], k=entry_per_category)\n",
    "        )\n",
    "    selected_labels = labels(task=tmp[\"task\"], golds=selected_labels)\n",
    "    new_output_path = (\n",
    "        dataset_output_path.rstrip(\".json\") + f\"_{entry_per_category}_{tag}.json\"\n",
    "    )\n",
    "    with open(new_output_path, \"w\", encoding=\"utf-8\") as new_output:\n",
    "        json.dump(selected_labels, new_output, cls=DTOEncoder, indent=4)\n",
    "\n",
    "    _, dataset_id, dataset_type, *_ = dataset_question_path.split(\"_\")\n",
    "\n",
    "    new_question_path = os.path.join(\n",
    "        default_data_path,\n",
    "        f\"LaMP_{dataset_id}_{dataset_type}_prompts_{tag}_{entry_per_category}.json\",\n",
    "    )\n",
    "    global counter, total, total_valid\n",
    "    with Progress() as prog:\n",
    "        task = prog.add_task(\"Parse Prompts\", total=100)\n",
    "        task_2 = prog.add_task(\"Parse Prompts (Only Valid)\", total=100)\n",
    "        prompt_dict = dict()\n",
    "        with open(dataset_question_path, \"r\", encoding=\"utf-8\") as question:\n",
    "            with open(new_question_path, \"w\", encoding=\"utf-8\") as new_question:\n",
    "                threads: List[Thread] = []\n",
    "                instances_queue = Queue()\n",
    "                msgs_queue = Queue()\n",
    "                total = 0\n",
    "                total_valid = 0\n",
    "\n",
    "                selected_ids = [label.id for label in selected_labels.golds]\n",
    "                selected_ids = sorted(selected_ids, key=lambda x: int(x))\n",
    "                print(selected_ids)\n",
    "                total_valid = len(selected_ids)\n",
    "                for i in range(worker_count):\n",
    "                    curr_worker = Thread(\n",
    "                        target=LaMP_2_extract_func,\n",
    "                        args=(\n",
    "                            prompt_dict,\n",
    "                            prog,\n",
    "                            task,\n",
    "                            task_2,\n",
    "                            selected_ids,\n",
    "                            instances_queue,\n",
    "                            msgs_queue,\n",
    "                            with_keyword_extraction\n",
    "                        ),\n",
    "                    )\n",
    "                    curr_worker.start()\n",
    "                    threads.append(curr_worker)\n",
    "                instances = json.load(question)\n",
    "                total = len(instances)\n",
    "                print(total, total_valid)\n",
    "                for instance in instances:\n",
    "                    instances_queue.put(instance)\n",
    "\n",
    "                for i in range(worker_count):\n",
    "                    instances_queue.put({\"id\": \"finished\"})\n",
    "                # while counter < total_valid:\n",
    "                # print(msgs_queue.get())\n",
    "                # continue\n",
    "                join_task = prog.add_task(\"Exiting Threads\", total=100)\n",
    "                [worker.join() for worker in threads]\n",
    "                prog.update(join_task, advance=100)\n",
    "                save_task = prog.add_task(\"Saving Prompts\", total=100)\n",
    "                json.dump(prompt_dict, new_question, indent=4)\n",
    "                prog.update(save_task, advance=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52fc9af97d3413ea726f13257c5d7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">['104', '10122', '10139', '10157', '10169', '10202', '10202', '10204', '10243', '10249', '10295', '10383', '10403',\n",
       "'10423', '10455', '10458', '10488', '10511', '10530', '10536', '10555', '10560', '10577', '10597', '10682', \n",
       "'10729', '10779', '10904', '10918', '10965', '10998', '101044', '101129', '101142', '101241', '101256', '101315', \n",
       "'101512', '101619', '101662', '101691', '101692', '101695', '101699', '101713', '101716', '101728', '101732', \n",
       "'101740', '101753', '101791', '101811', '101824', '101826', '101920', '102036', '102201', '102220', '102224', \n",
       "'102228', '102234', '102243', '102410', '102423', '102493', '102604', '102619', '102623', '102624', '102640', \n",
       "'102779', '102788', '102804', '102808', '102838', '102858', '102920', '102961', '102999', '103019', '103030', \n",
       "'103172', '103172', '103176', '103194', '103213', '103218', '103253', '103281', '103283', '103300', '103325', \n",
       "'103337', '103344', '103348', '103400', '103401', '103471', '103502', '103520', '103568', '103592', '103592', \n",
       "'103605', '103624', '103674', '103688', '103690', '103747', '103830', '103909', '103915', '104021', '104043', \n",
       "'104060', '104066', '104101', '104159', '104195', '104226', '104227', '104233', '104244', '104254', '104299', \n",
       "'104310', '104402', '104528', '104548', '104562', '104564', '104619', '104659', '104660', '104690', '104723', \n",
       "'104724', '104729', '104758', '104779', '104800', '104805', '104825', '104844', '105031', '105037', '105046', \n",
       "'105062', '105069', '105107', '105114', '105123', '105129', '105135', '105137', '105141', '105141', '105176', \n",
       "'105179', '105297', '105302', '105303', '105376', '105412', '105495', '105553', '105558', '105636', '105656', \n",
       "'105668', '105737', '105739', '105749', '105777', '105777', '105860', '105879', '105893', '105901', '105911']\n",
       "</pre>\n"
      ],
      "text/plain": [
       "['104', '10122', '10139', '10157', '10169', '10202', '10202', '10204', '10243', '10249', '10295', '10383', '10403',\n",
       "'10423', '10455', '10458', '10488', '10511', '10530', '10536', '10555', '10560', '10577', '10597', '10682', \n",
       "'10729', '10779', '10904', '10918', '10965', '10998', '101044', '101129', '101142', '101241', '101256', '101315', \n",
       "'101512', '101619', '101662', '101691', '101692', '101695', '101699', '101713', '101716', '101728', '101732', \n",
       "'101740', '101753', '101791', '101811', '101824', '101826', '101920', '102036', '102201', '102220', '102224', \n",
       "'102228', '102234', '102243', '102410', '102423', '102493', '102604', '102619', '102623', '102624', '102640', \n",
       "'102779', '102788', '102804', '102808', '102838', '102858', '102920', '102961', '102999', '103019', '103030', \n",
       "'103172', '103172', '103176', '103194', '103213', '103218', '103253', '103281', '103283', '103300', '103325', \n",
       "'103337', '103344', '103348', '103400', '103401', '103471', '103502', '103520', '103568', '103592', '103592', \n",
       "'103605', '103624', '103674', '103688', '103690', '103747', '103830', '103909', '103915', '104021', '104043', \n",
       "'104060', '104066', '104101', '104159', '104195', '104226', '104227', '104233', '104244', '104254', '104299', \n",
       "'104310', '104402', '104528', '104548', '104562', '104564', '104619', '104659', '104660', '104690', '104723', \n",
       "'104724', '104729', '104758', '104779', '104800', '104805', '104825', '104844', '105031', '105037', '105046', \n",
       "'105062', '105069', '105107', '105114', '105123', '105129', '105135', '105137', '105141', '105141', '105176', \n",
       "'105179', '105297', '105302', '105303', '105376', '105412', '105495', '105553', '105558', '105636', '105656', \n",
       "'105668', '105737', '105739', '105749', '105777', '105777', '105860', '105879', '105893', '105901', '105911']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">5914 180\n",
       "</pre>\n"
      ],
      "text/plain": [
       "5914 180\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selector(\n",
    "    dataset_question_path=\"./src/data/LaMP_2_train_questions.json\",\n",
    "    dataset_output_path=\"./src/data/LaMP_2_train_outputs.json\",\n",
    "    entry_per_category=12,\n",
    "    worker_count=16,\n",
    "    with_keyword_extraction=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('LaMP-RM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0dc0b78bb79ceedacc4b28a7c7a95f5c8ff7649848bf08868c2ee4cc7d3ac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
