{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "from queue import Queue, Empty\n",
    "import random\n",
    "from threading import Event, Thread\n",
    "import time\n",
    "from typing import Callable, Dict, List\n",
    "from src.utils import (\n",
    "    labels,\n",
    "    DTOEncoder,\n",
    "    task_2_categories,\n",
    "    default_data_path,\n",
    "    default_top_k_keywords,\n",
    ")\n",
    "from src.extraction import (\n",
    "    extract_instance_info_LaMP_1,\n",
    "    extract_instance_info_LaMP_2_alt,\n",
    "    extract_instance_info_LaMP_1_alt,\n",
    "    extract_instance_info_LaMP_2_alt_no_keyword,\n",
    ")\n",
    "from src.tokenization import lemma_tokenizer\n",
    "import os\n",
    "from threading import Lock\n",
    "from rich.progress import Progress, TaskID\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.22-caliber'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "next(wn.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_dict: Dict[str, str] = dict()\n",
    "total = 0\n",
    "total_valid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaMP_1_extract_func(\n",
    "    prompt_dict,\n",
    "    prog: Progress,\n",
    "    task: TaskID,\n",
    "    task_valid: TaskID,\n",
    "    id_list: List[str],\n",
    "    pipeline: Queue,\n",
    "    msg_pipe: Queue,\n",
    "    with_keyword_extraction: bool = True,\n",
    "    bm25_top_k: int = default_top_k_keywords,\n",
    "    text_rank_top_k_keywords: int = default_top_k_keywords,\n",
    "    context_top_k_keywords: int = default_top_k_keywords,\n",
    "):\n",
    "    global total, total_valid\n",
    "    while True:\n",
    "        instance: Dict[str, str] = pipeline.get()\n",
    "        if instance[\"id\"] == \"finished\":\n",
    "            break\n",
    "        if instance[\"id\"] in id_list:\n",
    "            prompt_dict[instance[\"id\"]] = extract_instance_info_LaMP_1_alt(\n",
    "                question=instance,\n",
    "                tokenizer=lemma_tokenizer,\n",
    "                keyword_extraction=with_keyword_extraction,\n",
    "                bm25_top_k=bm25_top_k,\n",
    "                text_rank_top_k_keywords=text_rank_top_k_keywords,\n",
    "                context_top_k_keywords=context_top_k_keywords,\n",
    "            )\n",
    "            prog.update(task_valid, advance=100 / total_valid)\n",
    "        prog.update(task, advance=100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaMP_2_extract_func(\n",
    "    prompt_dict,\n",
    "    prog: Progress,\n",
    "    task: TaskID,\n",
    "    task_valid: TaskID,\n",
    "    id_list: List[str],\n",
    "    pipeline: Queue,\n",
    "    msg_pipe: Queue,\n",
    "    with_keyword_extraction: bool = True,\n",
    "    category_top_k_keywords: int = default_top_k_keywords,\n",
    "    text_rank_top_k_keywords: int = default_top_k_keywords,\n",
    "    article_top_k: int = 1,\n",
    "):\n",
    "    global total, total_valid\n",
    "    while True:\n",
    "        instance: Dict[str, str] = pipeline.get()\n",
    "        if instance[\"id\"] == \"finished\":\n",
    "            break\n",
    "        if instance[\"id\"] in id_list:\n",
    "            prompt_dict[instance[\"id\"]] = extract_instance_info_LaMP_2_alt(\n",
    "                question=instance,\n",
    "                tokenizer=lemma_tokenizer,\n",
    "                keyword_extraction=with_keyword_extraction,\n",
    "                category_top_k_keywords=category_top_k_keywords,\n",
    "                text_rank_top_k_keywords=text_rank_top_k_keywords,\n",
    "                article_top_k=article_top_k,\n",
    "            )\n",
    "            prog.update(task_valid, advance=100 / total_valid)\n",
    "        prog.update(task, advance=100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector(\n",
    "    dataset_question_path: str,\n",
    "    dataset_output_path: str,\n",
    "    entry_per_category: int = 5,\n",
    "    worker_count: int = 5,\n",
    "    with_keyword_extraction: bool = True,\n",
    "    question_store_path: str = None,\n",
    "    output_store_path: str = None,\n",
    "    **params,\n",
    "):\n",
    "    tag = \"with_keyword\" if with_keyword_extraction else \"without_keyword\"\n",
    "    category_map = defaultdict(list)\n",
    "    with open(dataset_output_path, \"r\", encoding=\"utf-8\") as output:\n",
    "        tmp = json.load(output)\n",
    "        for label in tmp[\"golds\"]:\n",
    "            category_map[label[\"output\"]].append(label)\n",
    "\n",
    "    selected_labels = []\n",
    "    for category, doc_labels in category_map.items():\n",
    "        if len(doc_labels) <= entry_per_category:\n",
    "            selected_labels.extend(doc_labels)\n",
    "            continue\n",
    "        # elif category == \"business\":\n",
    "        #     continue\n",
    "        selected_labels.extend(\n",
    "            random.choices(category_map[category], k=entry_per_category)\n",
    "        )\n",
    "    selected_labels = labels(task=tmp[\"task\"], golds=selected_labels)\n",
    "\n",
    "    if output_store_path is None:\n",
    "        output_store_path = (\n",
    "            dataset_output_path.rstrip(\".json\") + f\"_{tag}_{entry_per_category}.json\"\n",
    "        )\n",
    "    with open(output_store_path, \"w\", encoding=\"utf-8\") as new_output:\n",
    "        json.dump(selected_labels, new_output, cls=DTOEncoder, indent=4)\n",
    "\n",
    "    _, dataset_id, dataset_type, *_ = dataset_question_path.split(\"_\")\n",
    "\n",
    "    if dataset_id == \"1\":\n",
    "        target_func = LaMP_1_extract_func\n",
    "    elif dataset_id == \"2\":\n",
    "        target_func = LaMP_2_extract_func\n",
    "    else:\n",
    "        raise NotImplementedError(\"Can only deal with LaMP_1 and LaMP_2 task\")\n",
    "\n",
    "    if question_store_path is None:\n",
    "        question_store_path = os.path.join(\n",
    "            default_data_path,\n",
    "            f\"LaMP_{dataset_id}_{dataset_type}_prompts_{tag}_{entry_per_category}.json\",\n",
    "        )\n",
    "    global total, total_valid\n",
    "    with Progress() as prog:\n",
    "        task = prog.add_task(\"Parse Prompts\", total=100)\n",
    "        task_2 = prog.add_task(\"Parse Prompts (Only Valid)\", total=100)\n",
    "        prompt_dict = dict()\n",
    "        with open(dataset_question_path, \"r\", encoding=\"utf-8\") as question:\n",
    "            with open(question_store_path, \"w\", encoding=\"utf-8\") as new_question:\n",
    "                threads: List[Thread] = []\n",
    "                instances_queue = Queue()\n",
    "                msgs_queue = Queue()\n",
    "                total = 0\n",
    "                total_valid = 0\n",
    "\n",
    "                selected_ids = [label.id for label in selected_labels.golds]\n",
    "                selected_ids = sorted(selected_ids, key=lambda x: int(x))\n",
    "                # print(selected_ids)\n",
    "                total_valid = len(selected_ids)\n",
    "                for i in range(worker_count):\n",
    "                    curr_worker = Thread(\n",
    "                        target=target_func,\n",
    "                        args=(\n",
    "                            prompt_dict,\n",
    "                            prog,\n",
    "                            task,\n",
    "                            task_2,\n",
    "                            selected_ids,\n",
    "                            instances_queue,\n",
    "                            msgs_queue,\n",
    "                            with_keyword_extraction,\n",
    "                        ),\n",
    "                        kwargs=params,\n",
    "                    )\n",
    "                    curr_worker.start()\n",
    "                    threads.append(curr_worker)\n",
    "                instances = json.load(question)\n",
    "                total = len(instances)\n",
    "                # print(total, total_valid)\n",
    "                for instance in instances:\n",
    "                    instances_queue.put(instance)\n",
    "\n",
    "                for i in range(worker_count):\n",
    "                    instances_queue.put({\"id\": \"finished\"})\n",
    "                join_task = prog.add_task(\"Exiting Threads\", total=100)\n",
    "                [worker.join() for worker in threads]\n",
    "                prog.update(join_task, advance=100)\n",
    "                save_task = prog.add_task(\"Saving Prompts\", total=100)\n",
    "                json.dump(prompt_dict, new_question, indent=4)\n",
    "                prog.update(save_task, advance=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "def task_1_selector():\n",
    "    dataset_question_path = \"./src/data/LaMP_1_train_questions.json\"\n",
    "    dataset_output_path = \"./src/data/LaMP_1_train_outputs.json\"\n",
    "    task_header = \"LaMP_1\"\n",
    "    store_dir = os.path.join(\"src\", \"data\", task_header)\n",
    "    os.makedirs(store_dir, exist_ok=True)\n",
    "\n",
    "    entry_per_category = 120\n",
    "    worker_count = 16\n",
    "\n",
    "    for text_rank_top_k_keywords in [5, 8, 10]:\n",
    "        for bm25_top_k in [5, 10]:\n",
    "            question_store_path = os.path.join(\n",
    "                store_dir,\n",
    "                f\"{task_header}_train_prompts_questions_with_keyword_{entry_per_category}_{text_rank_top_k_keywords}_{bm25_top_k}.json\",\n",
    "            )\n",
    "            output_store_path = os.path.join(\n",
    "                store_dir,\n",
    "                f\"{task_header}_train_outputs_selected_with_keyword_{entry_per_category}_{text_rank_top_k_keywords}_{bm25_top_k}.json\",\n",
    "            )\n",
    "            selector(\n",
    "                dataset_question_path=dataset_question_path,\n",
    "                dataset_output_path=dataset_output_path,\n",
    "                question_store_path=question_store_path,\n",
    "                output_store_path=output_store_path,\n",
    "                entry_per_category=entry_per_category,\n",
    "                worker_count=worker_count,\n",
    "                with_keyword_extraction=True,\n",
    "                bm25_top_k=bm25_top_k,\n",
    "                text_rank_top_k_keywords=text_rank_top_k_keywords,\n",
    "                context_top_k_keywords=ceil(\n",
    "                    (text_rank_top_k_keywords * bm25_top_k) / 2\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    for bm25_top_k in [2, 4]:\n",
    "        question_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_prompts_questions_without_keyword_{entry_per_category}_{bm25_top_k}.json\",\n",
    "        )\n",
    "        output_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_outputs_selected_without_keyword_{entry_per_category}_{bm25_top_k}.json\",\n",
    "        )\n",
    "        selector(\n",
    "            dataset_question_path=dataset_question_path,\n",
    "            dataset_output_path=dataset_output_path,\n",
    "            question_store_path=question_store_path,\n",
    "            output_store_path=output_store_path,\n",
    "            entry_per_category=entry_per_category,\n",
    "            worker_count=worker_count,\n",
    "            with_keyword_extraction=False,\n",
    "            bm25_top_k=bm25_top_k,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2_selector():\n",
    "    task_header = \"LaMP_2\"\n",
    "    store_dir = os.path.join(\"src\", \"data\", task_header)\n",
    "    os.makedirs(store_dir, exist_ok=True)\n",
    "    dataset_question_path = \"./src/data/LaMP_2_train_questions.json\"\n",
    "    dataset_output_path = \"./src/data/LaMP_2_train_outputs.json\"\n",
    "\n",
    "    entry_per_category = 16\n",
    "    worker_count = 16\n",
    "\n",
    "    for text_rank_top_k_keywords in [5, 8, 10]:\n",
    "        for category_top_k_keywords in [15, 30]:\n",
    "            question_store_path = os.path.join(\n",
    "                store_dir,\n",
    "                f\"{task_header}_train_prompts_questions_with_keyword_{entry_per_category}_{text_rank_top_k_keywords}_{category_top_k_keywords}.json\",\n",
    "            )\n",
    "            output_store_path = os.path.join(\n",
    "                store_dir,\n",
    "                f\"{task_header}_train_outputs_selected_with_keyword_{entry_per_category}_{text_rank_top_k_keywords}_{category_top_k_keywords}.json\",\n",
    "            )\n",
    "            selector(\n",
    "                dataset_question_path=dataset_question_path,\n",
    "                dataset_output_path=dataset_output_path,\n",
    "                question_store_path=question_store_path,\n",
    "                output_store_path=output_store_path,\n",
    "                entry_per_category=entry_per_category,\n",
    "                worker_count=worker_count,\n",
    "                with_keyword_extraction=True,\n",
    "                text_rank_top_k_keywords=text_rank_top_k_keywords,\n",
    "                category_top_k_keywords=category_top_k_keywords,\n",
    "            )\n",
    "\n",
    "    for article_top_k in [2, 4]:\n",
    "        question_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_prompts_questions_without_keyword_{entry_per_category}_{article_top_k}.json\",\n",
    "        )\n",
    "        output_store_path = os.path.join(\n",
    "            store_dir,\n",
    "            f\"{task_header}_train_outputs_selected_without_keyword_{entry_per_category}_{article_top_k}.json\",\n",
    "        )\n",
    "        selector(\n",
    "            dataset_question_path=dataset_question_path,\n",
    "            dataset_output_path=dataset_output_path,\n",
    "            question_store_path=question_store_path,\n",
    "            output_store_path=output_store_path,\n",
    "            entry_per_category=entry_per_category,\n",
    "            worker_count=worker_count,\n",
    "            with_keyword_extraction=False,\n",
    "            article_top_k=article_top_k,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa43e0113834c08b8b2f249a4ea60a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd3f75a5d564177966226ed2dc6df07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_1_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197876a328aa4677ba161efc43234183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b4ef428cc400bb2a81a4c0a8872eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_2_selector()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('LaMP-RM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0dc0b78bb79ceedacc4b28a7c7a95f5c8ff7649848bf08868c2ee4cc7d3ac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
